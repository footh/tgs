{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jfaath/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/jfaath/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/home/jfaath/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/jfaath/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "import tensorflow as tf\n",
    "# tf.enable_eager_execution()\n",
    "from tensorflow import gfile\n",
    "import numpy as np\n",
    "from tgs import data\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "np.set_printoptions(suppress=True,linewidth=np.nan,threshold=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = {\n",
    "    'train_file_pattern': '/home/jfaath/projects/tgs/data/train/tfrecord/tgs*',\n",
    "    'valid_file_pattern': '/home/jfaath/projects/tgs/data/train/tfrecord/tgs*',\n",
    "    'test_file_pattern': '/home/jfaath/projects/tgs/data/test/tfrecord/tgs*',\n",
    "    'shuf_buf': 50000,\n",
    "    'parallel_calls': 8,\n",
    "    'ext': {\n",
    "        'resize_dim': 128,\n",
    "        'resize_method': 'resize'\n",
    "    }\n",
    "}\n",
    "\n",
    "batch_size = 20\n",
    "num_epochs = 1\n",
    "\n",
    "def run_data(idi, mode=tf.estimator.ModeKeys.TRAIN, iters=None, resize_mth='pad'):\n",
    "    if iters is None:\n",
    "        iters = 999999\n",
    "    \n",
    "    sess = tf.InteractiveSession()\n",
    "    d = idi.input_fn(mode=mode)\n",
    "    cnt = 0\n",
    "    ids = []\n",
    "    imgs = []\n",
    "    masks = []\n",
    "    resizes = []\n",
    "    while True:\n",
    "        try:\n",
    "            img_dict, mask = sess.run(d)\n",
    "            ids.extend(img_dict['id'])\n",
    "            imgs.extend(img_dict['img'])\n",
    "            masks.extend(mask)\n",
    "            resizes.extend(img_dict[resize_mth])\n",
    "            cnt += 1\n",
    "            if cnt > iters:\n",
    "                break\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(f\"Epoch finished on iteration {cnt}\")\n",
    "            break\n",
    "\n",
    "    sess.close()\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    return ids, np.asarray(imgs), np.asarray(masks), np.asarray(resizes)\n",
    "\n",
    "\n",
    "def plot_images_and_masks(ids, imgs, masks, count=4):\n",
    "    fig, axes = plt.subplots(nrows=count, ncols=2, figsize=(10, 10 * (count // 2)), sharex=True, sharey=True)\n",
    "    ax = axes.ravel()\n",
    "\n",
    "    for i in range(count):\n",
    "        ax[i * 2].imshow(imgs[i], cmap=plt.cm.gray, interpolation='none', aspect='auto')\n",
    "        ax[i * 2].set_title(ids[i].decode())\n",
    "        ax[i * 2 + 1].imshow(masks[i], cmap=plt.cm.gray, interpolation='none', aspect='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:File pattern: /home/jfaath/projects/tgs/data/train/tfrecord/tgs*\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'pad'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-296badc46e9a>\u001b[0m in \u001b[0;36mrun_data\u001b[0;34m(idi, mode, iters, resize_mth)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mmasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mresizes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresize_mth\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mcnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcnt\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0miters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'pad'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "idi = data.ImageDataInput(config_dict,\n",
    "                          batch_size=batch_size,\n",
    "                          num_epochs=num_epochs,\n",
    "                          preprocess=False,\n",
    "                          augment=False)\n",
    "\n",
    "ids, imgs, masks, resizes = run_data(idi, iters=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images_and_masks(ids, imgs, masks, count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "\n",
    "print('IMAGES')\n",
    "print(f'shape: {imgs[idx].shape}, dtype: {imgs[idx].dtype}')\n",
    "print(f'min: {np.min(imgs[idx])}, max: {np.max(imgs[idx])}')\n",
    "print('MASKS')\n",
    "print(f'shape: {masks[idx].shape}, dtype: {masks[idx].dtype}')\n",
    "print(f'min: {np.min(masks[1])}, max: {np.max(masks[1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ids[0])\n",
    "print(resizes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
